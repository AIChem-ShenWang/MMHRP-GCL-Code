{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"e2lHTf8uPqqE"},"id":"e2lHTf8uPqqE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install rdkit==2024.9.5\n","!pip install torch_geometric==2.5.3"],"metadata":{"id":"qhXzEdysP0HC"},"id":"qhXzEdysP0HC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import torch\n","sys.path.append(\"/content/drive/MyDrive/MMHRP-GCL-Code\")\n","from utils.rxn import *\n","from utils.molecule import *\n","from torch_geometric.loader import DataLoader\n","from models.MMHRP_GCL import *\n","import time\n","from tqdm import tqdm\n","import datetime\n","import warnings\n","warnings.simplefilter('ignore')"],"metadata":{"id":"nC7RWcReP1YC"},"id":"nC7RWcReP1YC","execution_count":null,"outputs":[]},{"cell_type":"code","source":["rs_list = [1,2,3,4,5]\n","\n","for rs in rs_list:\n","    # 1. import data\n","    data = pd.read_excel(\"/content/drive/MyDrive/MMHRP-GCL-Code/data/Suzuki_HTE/Suzuki_HTE_data.xlsx\")\n","    random_state = rs\n","    data = data.sample(random_state=random_state, frac=1).reset_index(drop=True)\n","    vocab_type = \"Suzuki\"\n","    vocab_path = \"/content/drive/MyDrive/MMHRP-GCL-Code/utils/%s_vocab.txt\" % vocab_type\n","\n","    # Generate Rxnsmi\n","    rxn_RxnSmi = list()\n","    max_len = -1\n","    for batch in range(data.shape[0]):\n","        RxnSmi = get_Suzuki_RxnSmi(data.iloc[batch, :])\n","        max_len = max(max_len, len(RxnSmi))\n","        RxnSmi = \" \".join(smi_tokenizer(RxnSmi))\n","        rxn_RxnSmi.append(RxnSmi)\n","\n","    rxn_dataset = list()\n","    smi_inputsize = 128\n","\n","    for batch in tqdm(range(data.shape[0])):\n","        meta = list()\n","        # rea\n","        rea1 = data.loc[batch][\"Reactant_1_Name\"]\n","        rea2 = data.loc[batch][\"Reactant_2_Name\"]\n","        meta.append(smis_to_graph([rea1, rea2]))\n","        # add\n","        add = list()\n","\n","        base = data.loc[batch][\"Reagent_1_Short_Hand\"]\n","        if not pd.isnull(base):\n","            add.append(base)\n","        ligand = data.loc[batch][\"Ligand_Short_Hand\"]\n","        if not pd.isnull(ligand):\n","            add.append(ligand)\n","        sol = data.loc[batch][\"Solvent_1_Short_Hand\"]\n","        if not pd.isnull(sol):\n","            add.append(sol)\n","\n","        meta.append(smis_to_graph(add))\n","\n","        # RxnSmi\n","        RxnSmi_vec = RxnSmi_to_tensor(RxnSmi=rxn_RxnSmi[batch], maxlen_=max_len, victor_size=smi_inputsize,\n","                                      file=vocab_path)\n","        meta.append(RxnSmi_vec)\n","\n","        # yield\n","        meta.append(data.loc[batch][\"Product_Yield_PCT_Area_UV\"] / 100)\n","\n","        rxn_dataset.append(meta)\n","\n","    # report\n","    dir_path = \"/content/drive/MyDrive/MMHRP-GCL-Code/exp/Suzuki/Suzuki_MMHRP_rs=%s_%s\" % (\n","    random_state, datetime.datetime.now())\n","    os.mkdir(\"%s\" % dir_path)\n","    f = open(\"%s/Model_Training_Report.txt\" % dir_path, mode=\"w\")\n","\n","    # split of train & test set\n","    ratio = 0.7\n","    batch_size = 72\n","    batch = len(rxn_dataset)\n","    train_set = rxn_dataset[0: int(ratio * batch)]\n","    test_set = rxn_dataset[int(ratio * batch) + 1:]\n","    # data_loader\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n","\n","    test_RMSE = list()\n","    test_R2 = list()\n","    test_MAE = list()\n","    train_R2 = list()\n","    train_RMSE = list()\n","    train_MAE = list()\n","    pred = list()\n","    true = list()\n","\n","    # 3. training of the model\n","    # params\n","    t = 700\n","    lr = 1e-3\n","    num_feature = 8\n","    smi_inputsize = 128\n","\n","    # use gpu\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # model\n","    model = MMHRP_GCL(\n","      GraphEncoder={\n","        \"NodeFeatNum\":num_feature,\n","        \"Channels\":[32, 64],\n","        \"Heads\":4\n","      },\n","      TextEncoder={\n","        \"SmiFeatNum\":smi_inputsize,\n","        \"Heads\":4,\n","        \"BigruChannels\":[128, 128, 128],\n","        \"BigruNumlayer\":1\n","      },\n","      Decoder = {\n","        \"Heads\":4,\n","        \"Channels\":[1000, 500, 100]\n","      },\n","      device=device\n","    )\n","\n","    opti = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n","    model = model.to(device)\n","    criterion = nn.MSELoss()\n","\n","    # writedown params\n","    f.write(\"params:\\n\")\n","    f.write(\"random_state=%s\\n\" % random_state)\n","    f.write(\"ratio=%s\\n\" % ratio)\n","    f.write(\"batch_size=%s\\n\" % batch_size)\n","    f.write(\"t=%s\\n\" % t)\n","    f.write(\"lr=%s\\n\" % lr)\n","    f.write(\"vocab_type=%s\\n\" % vocab_type)\n","\n","    # Training\n","\n","    # best performance\n","    best = [0, 0, 0, 0, 0, 0, [], [],\n","            []]  # train_R2, train_RMSE, train_MAE, test_R2, test_RMSE, test_MAE test_predict, test_true, model\n","\n","    f.write(\"\\nStart training\\n\")\n","\n","    for epoch in tqdm(range(t)):\n","        if epoch == 200:\n","          opti = torch.optim.Adam(model.parameters(), lr=lr/10, weight_decay=1e-5)\n","        # Training\n","        global_loss = torch.tensor([0.])\n","\n","        for data in train_loader:\n","            x = [i.to(device) for i in data[:-1]]\n","            y = torch.unsqueeze(data[-1], dim=1).to(device)\n","            loss = criterion(model.forward(x), y)\n","            opti.zero_grad()\n","            loss.backward()\n","            opti.step()\n","            global_loss += loss.item()\n","\n","        # record of loss during training\n","        # performance in train set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in train_loader:\n","                x = [i.to(device) for i in data[:-1]]\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(model.forward(x).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            train_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            train_R2.append(R2(np.array(pred), np.array(true)))\n","            train_MAE.append(MAE(np.array(true), np.array(pred)))\n","\n","        # performance in test set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in test_loader:\n","                x = [i.to(device) for i in data[:-1]]\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(model.forward(x).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            test_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            test_R2.append(R2(np.array(pred), np.array(true)))\n","            test_MAE.append(MAE(np.array(true), np.array(pred)))\n","\n","            if epoch == 0 or test_R2[-1] > best[3]:\n","                best = [train_R2[-1], train_RMSE[-1], train_MAE[-1], test_R2[-1], test_RMSE[-1], test_MAE[-1], pred,\n","                        true, model]\n","\n","        # write report\n","        f.write(\n","            \"Epoch:%d loss: %f, R2:train set %.3f\\ttest set %.3f\\tRMSE:train set %.3f\\ttest set %.3f\\tMAE:train set %.3f\\ttest set %.3f\\n\" % (\n","            epoch + 1, global_loss / batch_size, train_R2[-1], test_R2[-1], train_RMSE[-1], test_RMSE[-1],\n","            train_MAE[-1], test_MAE[-1]))\n","\n","    # 4.Evaluation\n","    f.write(\"\\n\")\n","    # Performance in train set\n","    f.write(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_R2[-10:]).mean(), np.array(train_R2[-10:]).std(), best[0]))\n","    f.write(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_RMSE[-10:]).mean(), np.array(train_RMSE[-10:]).std(), best[1]))\n","    f.write(\"MAE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_MAE[-10:]).mean(), np.array(train_MAE[-10:]).std(), best[2]))\n","\n","    # Performance in test set\n","    f.write(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(test_R2[-10:]).mean(), np.array(test_R2[-10:]).std(), best[3]))\n","    f.write(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_RMSE[-10:]).mean(), np.array(test_RMSE[-10:]).std(), best[4]))\n","    f.write(\"MAE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_MAE[-10:]).mean(), np.array(test_MAE[-10:]).std(), best[5]))\n","\n","    f.close()\n","\n","    # Performance in train set\n","    print(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_R2[-10:]).mean(), np.array(train_R2[-10:]).std(), best[0]))\n","    print(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_RMSE[-10:]).mean(), np.array(train_RMSE[-10:]).std(), best[1]))\n","    print(\"MAE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_MAE[-10:]).mean(), np.array(train_MAE[-10:]).std(), best[2]))\n","\n","    # Performance in test set\n","    print(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(test_R2[-10:]).mean(), np.array(test_R2[-10:]).std(), best[3]))\n","    print(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_RMSE[-10:]).mean(), np.array(test_RMSE[-10:]).std(), best[4]))\n","    print(\"MAE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_MAE[-10:]).mean(), np.array(test_MAE[-10:]).std(), best[5]))\n","\n","    # 5.Figure\n","    import matplotlib.pyplot as plt\n","    import seaborn as sns\n","\n","    fig = plt.figure(dpi=500, figsize=(10, 5))\n","\n","    # Training Fig\n","    plt.subplot(1, 2, 1)\n","    steps = np.linspace(1, t, t)\n","    plt.plot(steps, train_R2, color=[236 / 255, 164 / 255, 124 / 255])\n","    plt.plot(steps, test_R2, color=[117 / 255, 157 / 255, 219 / 255])\n","    # Beautify\n","    plt.legend([\"train set\", \"test set\"], loc=\"upper left\", prop={'size': 8})\n","    plt.xlabel(\"Epoch\", fontsize=10)\n","    plt.ylabel(\"R$^2$\", fontsize=10)\n","    plt.title(\"The R$^2$ of train & test set during training\", fontsize=13)\n","\n","    # Test set performance\n","    plt.subplot(1, 2, 2)\n","    tr = np.array(best[7]).flatten() * 100\n","    pr = np.array(best[6]).flatten() * 100\n","    plt.scatter(pr, tr, alpha=0.7, marker=\".\")\n","    plt.xlabel(\"Predicted Yield\", fontsize=10)\n","    plt.ylabel(\"Observed Yield\", fontsize=10)\n","    x = np.linspace(0, 100, 100)\n","    y = np.linspace(0, 100, 100)\n","    plt.plot(x, y, linestyle=\"--\", color=\"r\")\n","    plt.title(\"Test set performance\", fontsize=15)\n","    fig.suptitle(\"MMHRP for Suzuki dataset\", fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(\"%s/Performance_Figure.png\" % dir_path)\n","    plt.show()\n","\n","    torch.save(best[-1], \"%s/model.pth\" % dir_path)"],"metadata":{"id":"6wR_WIHaRqeu"},"id":"6wR_WIHaRqeu","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}