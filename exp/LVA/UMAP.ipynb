{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fi0BzzQCUro3"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install rdkit==2024.9.5\n","!pip install torch_geometric==2.5.3\n","!pip install umap-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZV2ECyTU4Zs"},"outputs":[],"source":["# Modality Vector Generator\n","import os\n","import sys\n","import torch\n","sys.path.append(\"/content/drive/MyDrive/MMHRP-GCL-Code\")\n","from utils.rxn import *\n","from utils.molecule import *\n","from torch_geometric.loader import DataLoader\n","from models.GNN_Models import *\n","import time\n","from tqdm import tqdm\n","import datetime\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","import umap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DVxG9WomrHe"},"outputs":[],"source":["colors = [[114/255, 188/255, 213/255], [170/255, 220/255, 224/255], [231/255, 98/255, 84/255]]\n","\n","def get_embed_vec(model, x):\n","\n","  # Graph Modality\n","  graph_emb1 = model.ReaProEncoder(x[0])\n","  graph_emb2 = model.CatSolEncoder(x[1])\n","\n","  # Text Modality\n","  text_embed = model.RxnSmiEncoder(x[2])\n","\n","  return graph_emb1, graph_emb2, text_embed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4L7NahQvVSkL"},"outputs":[],"source":["# BH\n","# 1. import data\n","data = pd.read_excel(\"/content/drive/MyDrive/MMHRP-GCL-Code/data/BH_HTE/BH_HTE_data.xlsx\")\n","vocab_type = \"BH\"\n","vocab_path = \"/content/drive/MyDrive/MMHRP-GCL-Code/utils/%s_vocab.txt\" % vocab_type\n","\n","# 2. build dataset & dataloader\n","\n","rxn_RxnSmi = list()\n","max_len = -1\n","for batch in range(data.shape[0]):\n","    RxnSmi = get_Buchwald_RxnSmi(data.iloc[batch, :])\n","    max_len = max(max_len, len(RxnSmi))\n","    RxnSmi = \" \".join(smi_tokenizer(RxnSmi))\n","    rxn_RxnSmi.append(RxnSmi)\n","\n","rxn_dataset = list()\n","smi_inputsize = 128\n","\n","for batch in tqdm(range(data.shape[0])):\n","    meta = list()\n","    # rea\n","    rea = data.loc[batch][\"aryl_halide_smiles\"]\n","    pro = data.loc[batch][\"product_smiles\"]\n","    meta.append(smis_to_graph([rea, pro]))\n","    # add\n","    base = data.loc[batch][\"base_smiles\"]\n","    ligand = data.loc[batch][\"ligand_smiles\"]\n","    additive = data.loc[batch][\"additive_smiles\"]\n","    meta.append(smis_to_graph([base, ligand, additive]))\n","    # RxnSmi\n","    RxnSmi_vec = RxnSmi_to_tensor(RxnSmi=rxn_RxnSmi[batch], maxlen_=max_len, victor_size=smi_inputsize,\n","                                  file=vocab_path)\n","    meta.append(RxnSmi_vec)\n","\n","    # yield\n","    meta.append(data.loc[batch][\"yield\"] / 100)\n","\n","    rxn_dataset.append(meta)\n","\n","# import model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = torch.load(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/BH_model.pth\", map_location=device).eval()\n","\n","emb_vecs = []\n","info = DataLoader(rxn_dataset, batch_size=1)\n","for i in info:\n","    x = [j.to(device) for j in i[:-1]]\n","    graph_emb1, graph_emb2, text_emb = get_embed_vec(model, x)\n","    emb_vecs.append(np.array(graph_emb1.detach().cpu()))\n","    emb_vecs.append(np.array(graph_emb2.detach().cpu()))\n","    emb_vecs.append(np.array(text_emb.detach().cpu()))\n","\n","emb_vecs = np.array(emb_vecs).reshape(-1, 128)\n","# DR\n","reducer = umap.UMAP(n_components=2)\n","embedding = reducer.fit_transform(emb_vecs)\n","plt.figure(figsize=(5, 5), dpi=200)\n","for i in tqdm(range(0, embedding.shape[0], 3)):\n","  a = plt.scatter(embedding[i, 0], embedding[i, 1], color=colors[0])\n","  b = plt.scatter(embedding[i+1, 0], embedding[i+1, 1],color=colors[1])\n","  c = plt.scatter(embedding[i+2, 0], embedding[i+2, 1],color=colors[2])\n","labels = [a, b, c]\n","plt.title('UMAP projection of the latent vectors in B-H dataset')\n","plt.legend(labels, [\"Graph Modality\\n(Reactans&Products)\", \"Graph Modality\\n(Catalysts&Solvents)\", \"Text Modality\"], loc=\"upper right\", prop={'size': 6})\n","plt.xlabel(\"UMAP 1\", fontsize=10)\n","plt.ylabel(\"UMAP 2\", fontsize=10)\n","plt.xticks([])\n","plt.yticks([])\n","plt.savefig(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/BH_umap.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_PbG6rfVuxX"},"outputs":[],"source":["# Suzuki\n","# 1. import data\n","data = pd.read_excel(\"/content/drive/MyDrive/MMHRP-GCL-Code/data/Suzuki_HTE/Suzuki_HTE_data.xlsx\")\n","vocab_type = \"Suzuki\"\n","vocab_path = \"/content/drive/MyDrive/MMHRP-GCL-Code/utils/%s_vocab.txt\" % vocab_type\n","\n","# Generate Rxnsmi\n","rxn_RxnSmi = list()\n","max_len = -1\n","for batch in range(data.shape[0]):\n","    RxnSmi = get_Suzuki_RxnSmi(data.iloc[batch, :])\n","    max_len = max(max_len, len(RxnSmi))\n","    RxnSmi = \" \".join(smi_tokenizer(RxnSmi))\n","    rxn_RxnSmi.append(RxnSmi)\n","\n","rxn_dataset = list()\n","smi_inputsize = 128\n","\n","for batch in tqdm(range(data.shape[0])):\n","    meta = list()\n","    # rea\n","    rea1 = data.loc[batch][\"Reactant_1_Name\"]\n","    rea2 = data.loc[batch][\"Reactant_2_Name\"]\n","    meta.append(smis_to_graph([rea1, rea2]))\n","    # add\n","    add = list()\n","\n","    base = data.loc[batch][\"Reagent_1_Short_Hand\"]\n","    if not pd.isnull(base):\n","        add.append(base)\n","    ligand = data.loc[batch][\"Ligand_Short_Hand\"]\n","    if not pd.isnull(ligand):\n","        add.append(ligand)\n","    sol = data.loc[batch][\"Solvent_1_Short_Hand\"]\n","    if not pd.isnull(sol):\n","        add.append(sol)\n","\n","    meta.append(smis_to_graph(add))\n","\n","    # RxnSmi\n","    RxnSmi_vec = RxnSmi_to_tensor(RxnSmi=rxn_RxnSmi[batch], maxlen_=max_len, victor_size=smi_inputsize,\n","                                  file=vocab_path)\n","    meta.append(RxnSmi_vec)\n","\n","    # yield\n","    meta.append(data.loc[batch][\"Product_Yield_PCT_Area_UV\"] / 100)\n","\n","    rxn_dataset.append(meta)\n","\n","# import model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = torch.load(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/Suzuki_model.pth\", map_location=device).eval()\n","\n","emb_vecs = []\n","info = DataLoader(rxn_dataset, batch_size=1)\n","for i in info:\n","    x = [j.to(device) for j in i[:-1]]\n","    graph_emb1, graph_emb2, text_emb = get_embed_vec(model, x)\n","    emb_vecs.append(np.array(graph_emb1.detach().cpu()))\n","    emb_vecs.append(np.array(graph_emb2.detach().cpu()))\n","    emb_vecs.append(np.array(text_emb.detach().cpu()))\n","\n","emb_vecs = np.array(emb_vecs).reshape(-1, 128)\n","# DR\n","reducer = umap.UMAP(n_components=2)\n","embedding = reducer.fit_transform(emb_vecs)\n","plt.figure(figsize=(5, 5), dpi=200)\n","for i in tqdm(range(0, embedding.shape[0], 3)):\n","  a = plt.scatter(embedding[i, 0], embedding[i, 1], color=colors[0])\n","  b = plt.scatter(embedding[i+1, 0], embedding[i+1, 1],color=colors[1])\n","  c = plt.scatter(embedding[i+2, 0], embedding[i+2, 1],color=colors[2])\n","labels = [a, b, c]\n","plt.title('UMAP projection of the latent vectors in S-M dataset')\n","plt.legend(labels, [\"Graph Modality\\n(Reactans&Products)\", \"Graph Modality\\n(Catalysts&Solvents)\", \"Text Modality\"], loc=\"upper right\", prop={'size': 6})\n","plt.xlabel(\"UMAP 1\", fontsize=10)\n","plt.ylabel(\"UMAP 2\", fontsize=10)\n","plt.xticks([])\n","plt.yticks([])\n","plt.savefig(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/SM_umap.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fV3dpP8Vu6z"},"outputs":[],"source":["# AT\n","# 1. import data\n","data = pd.read_csv(\"/content/drive/MyDrive/MMHRP-GCL-Code/data/AT/Asymmetric_Thiol_Addition.csv\")\n","vocab_type = \"AT\"\n","vocab_path = \"/content/drive/MyDrive/MMHRP-GCL-Code/utils/%s_vocab.txt\" % vocab_type\n","\n","# Generate Rxnsmi\n","rxn_RxnSmi = list()\n","max_len = -1\n","for batch in range(data.shape[0]):\n","    RxnSmi = get_AT_RxnSmi(data.iloc[batch, :])\n","    max_len = max(max_len, len(RxnSmi))\n","    RxnSmi = \" \".join(smi_tokenizer(RxnSmi))\n","    rxn_RxnSmi.append(RxnSmi)\n","\n","rxn_dataset = list()\n","smi_inputsize = 128\n","\n","for batch in tqdm(range(data.shape[0])):\n","    meta = list()\n","    # rea\n","    rea1 = data.loc[batch][\"Imine\"]\n","    rea2 = data.loc[batch][\"Thiol\"]\n","    prod = data.loc[batch][\"product\"]\n","    meta.append(smis_to_graph([rea1, rea2, prod]))\n","    # add\n","    add = list()\n","\n","    cat = data.loc[batch][\"Catalyst\"]\n","    add.append(cat)\n","\n","    meta.append(smis_to_graph(add))\n","\n","    # RxnSmi\n","    RxnSmi_vec = RxnSmi_to_tensor(RxnSmi=rxn_RxnSmi[batch], maxlen_=max_len, victor_size=smi_inputsize,\n","                                  file=vocab_path)\n","    meta.append(RxnSmi_vec)\n","\n","    # yield\n","    meta.append(data.loc[batch][\"Output\"])\n","\n","    rxn_dataset.append(meta)\n","\n","# import model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = torch.load(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/AT_model.pth\", map_location=device).eval()\n","\n","emb_vecs = []\n","info = DataLoader(rxn_dataset, batch_size=1)\n","for i in info:\n","    x = [j.to(device) for j in i[:-1]]\n","    graph_emb1, graph_emb2, text_emb = get_embed_vec(model, x)\n","    emb_vecs.append(np.array(graph_emb1.detach().cpu()))\n","    emb_vecs.append(np.array(graph_emb2.detach().cpu()))\n","    emb_vecs.append(np.array(text_emb.detach().cpu()))\n","\n","emb_vecs = np.array(emb_vecs).reshape(-1, 128)\n","# DR\n","reducer = umap.UMAP(n_components=2)\n","embedding = reducer.fit_transform(emb_vecs)\n","plt.figure(figsize=(5, 5), dpi=200)\n","for i in tqdm(range(0, embedding.shape[0], 3)):\n","  a = plt.scatter(embedding[i, 0], embedding[i, 1], color=colors[0])\n","  b = plt.scatter(embedding[i+1, 0], embedding[i+1, 1],color=colors[1])\n","  c = plt.scatter(embedding[i+2, 0], embedding[i+2, 1],color=colors[2])\n","labels = [a, b, c]\n","plt.title('UMAP projection of the latent vectors in A-T dataset')\n","plt.legend(labels, [\"Graph Modality\\n(Reactans&Products)\", \"Graph Modality\\n(Catalysts&Solvents)\", \"Text Modality\"], loc=\"upper right\", prop={'size': 6})\n","plt.xlabel(\"UMAP 1\", fontsize=10)\n","plt.ylabel(\"UMAP 2\", fontsize=10)\n","plt.xticks([])\n","plt.yticks([])\n","plt.savefig(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/AT_umap.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_Cp2q5NyV8sl"},"outputs":[],"source":["# SNAr\n","# 1. import data\n","data = pd.read_excel(\"/content/drive/MyDrive/MMHRP-GCL-Code/data/SNAR/SNAR_data.xlsx\")\n","vocab_type = \"SNAR\"\n","vocab_path = \"/content/drive/MyDrive/MMHRP-GCL-Code/utils/%s_vocab.txt\" % vocab_type\n","\n","# Generate Rxnsmi\n","rxn_RxnSmi = list()\n","max_len = -1\n","for batch in range(data.shape[0]):\n","    RxnSmi = get_SNAR_RxnSmi(data.iloc[batch, :])\n","    max_len = max(max_len, len(RxnSmi))\n","    RxnSmi = \" \".join(smi_tokenizer(RxnSmi))\n","    rxn_RxnSmi.append(RxnSmi)\n","\n","rxn_dataset = list()\n","smi_inputsize = 128\n","\n","for batch in tqdm(range(data.shape[0])):\n","    meta = list()\n","    # rea\n","    rea1 = data.loc[batch][\"Substrate SMILES\"]\n","    rea2 = data.loc[batch][\"Nucleophile SMILES\"]\n","    prod = data.loc[batch][\"Product SMILES\"]\n","    meta.append(smis_to_graph([rea1, rea2, prod]))\n","    # sol\n","    sol = list()\n","\n","    sol = data.loc[batch][\"Solvent\"].split(\".\")\n","\n","    meta.append(smis_to_graph(sol))\n","\n","    # RxnSmi\n","    RxnSmi_vec = RxnSmi_to_tensor(RxnSmi=rxn_RxnSmi[batch], maxlen_=max_len, victor_size=smi_inputsize,\n","                                  file=vocab_path)\n","    meta.append(RxnSmi_vec)\n","\n","    # activation energy\n","    meta.append(data.loc[batch][\"exp_activation_energy\"])\n","\n","    rxn_dataset.append(meta)\n","\n","# import model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = torch.load(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/SNAR_model.pth\", map_location=device).eval()\n","\n","emb_vecs = []\n","info = DataLoader(rxn_dataset, batch_size=1)\n","for i in info:\n","    x = [j.to(device) for j in i[:-1]]\n","    graph_emb1, graph_emb2, text_emb = get_embed_vec(model, x)\n","    emb_vecs.append(np.array(graph_emb1.detach().cpu()))\n","    emb_vecs.append(np.array(graph_emb2.detach().cpu()))\n","    emb_vecs.append(np.array(text_emb.detach().cpu()))\n","\n","emb_vecs = np.array(emb_vecs).reshape(-1, 128)\n","# DR\n","reducer = umap.UMAP(n_components=2)\n","embedding = reducer.fit_transform(emb_vecs)\n","plt.figure(figsize=(5, 5), dpi=200)\n","for i in tqdm(range(0, embedding.shape[0], 3)):\n","  a = plt.scatter(embedding[i, 0], embedding[i, 1], color=colors[0])\n","  b = plt.scatter(embedding[i+1, 0], embedding[i+1, 1],color=colors[1])\n","  c = plt.scatter(embedding[i+2, 0], embedding[i+2, 1],color=colors[2])\n","labels = [a, b, c]\n","plt.title('UMAP projection of the latent vectors in S$_N$Ar dataset')\n","plt.legend(labels, [\"Graph Modality\\n(Reactans&Products)\", \"Graph Modality\\n(Catalysts&Solvents)\", \"Text Modality\"], loc=\"upper right\", prop={'size': 6})\n","plt.xlabel(\"UMAP 1\", fontsize=10)\n","plt.ylabel(\"UMAP 2\", fontsize=10)\n","plt.xticks([])\n","plt.yticks([])\n","plt.savefig(\"/content/drive/MyDrive/MMHRP-GCL-Code/exp/LVA/SNAR_umap.png\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}