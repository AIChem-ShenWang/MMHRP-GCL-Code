{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jO0ADPbfdK-2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZ_l9Xw7dRul"},"outputs":[],"source":["!pip install rdkit\n","!pip install torch_geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_7VqI72dSrP"},"outputs":[],"source":["import os\n","import sys\n","import torch\n","sys.path.append(\"/content/drive/MyDrive/MMHRP\")\n","from utils.rxn import *\n","from utils.molecule import *\n","from torch_geometric.loader import DataLoader\n","from models.GNN_Models import *\n","import time\n","from tqdm import tqdm\n","import datetime\n","from sklearn.metrics import mean_absolute_error as MAE\n","import warnings\n","warnings.simplefilter('ignore')\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZ8g-mIEdUyJ"},"outputs":[],"source":["# GCN\n","rs_list = [1]\n","\n","for rs in rs_list:\n","    # 1. import data\n","    data = pd.read_excel(\"/content/drive/MyDrive/MMHRP/data/SNAR/SNAR_data.xlsx\")\n","    random_state = rs\n","\n","    data = data.sample(random_state=random_state, frac=1).reset_index(drop=True)\n","\n","    # 2. build dataset & dataloader\n","    rxn_dataset = list()\n","\n","    for batch in tqdm(range(data.shape[0])):\n","        meta = list()\n","        # rea\n","        rea1 = data.loc[batch][\"Substrate SMILES\"]\n","        rea2 = data.loc[batch][\"Nucleophile SMILES\"]\n","        prod = data.loc[batch][\"Product SMILES\"]\n","        # sol\n","        sol = list()\n","        sol = data.loc[batch][\"Solvent\"].split(\".\")\n","\n","        meta.append(smis_to_graph([rea1, rea2, prod] + sol))\n","\n","        # activation energy\n","        meta.append(data.loc[batch][\"exp_activation_energy\"])\n","\n","        rxn_dataset.append(meta)\n","\n","    # report\n","    dir_path = \"/content/drive/MyDrive/MMHRP/exp/SNAR/SNAR_GCN_rs=%s_%s\" % (random_state, datetime.datetime.now())\n","    os.mkdir(\"%s\" % dir_path)\n","    f = open(\"%s/Model_Training_Report.txt\" % dir_path, mode=\"w\")\n","\n","    # split of train & test set\n","    ratio = 0.7\n","    batch_size = 64\n","    batch = len(rxn_dataset)\n","    train_set = rxn_dataset[0: int(ratio * batch)]\n","    test_set = rxn_dataset[int(ratio * batch) + 1:]\n","    # data_loader\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n","\n","    test_RMSE = list()\n","    test_R2 = list()\n","    test_MAE = list()\n","    train_R2 = list()\n","    train_RMSE = list()\n","    train_MAE = list()\n","    pred = list()\n","    true = list()\n","\n","    # 3. training of the model\n","    # params\n","    t = 1\n","    lr = 1e-3\n","    num_feature = 8\n","\n","    # use gpu\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # model\n","    model = GCN(node_feature_num=num_feature,\n","                channels=[32, 64])\n","    model = model.to(device)\n","    opti = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n","\n","    criterion = nn.MSELoss()\n","\n","    # writedown params\n","    f.write(\"params:\\n\")\n","    f.write(\"random_state=%s\\n\" % random_state)\n","    f.write(\"ratio=%s\\n\" % ratio)\n","    f.write(\"batch_size=%s\\n\" % batch_size)\n","    f.write(\"t=%s\\n\" % t)\n","    f.write(\"lr=%s\\n\" % lr)\n","\n","    # Training\n","\n","    # best performance\n","    best = [0, 0, 0, 0, 0, 0, [], [],\n","            []]  # train_R2, train_RMSE, train_MAE, test_R2, test_RMSE, test_MAE test_predict, test_true, model\n","\n","    f.write(\"\\nStart training\\n\")\n","\n","    for epoch in tqdm(range(t)):\n","        # Training\n","        global_loss = torch.tensor([0.])\n","\n","        for data in train_loader:\n","            x = [i.to(device) for i in data[:-1]]\n","            y = torch.unsqueeze(data[-1], dim=1).to(device)\n","            loss = criterion(model.forward(x[0]), y)\n","            opti.zero_grad()\n","            loss.backward()\n","            opti.step()\n","            global_loss += loss.item()\n","\n","        # record of loss during training\n","        # performance in train set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in train_loader:\n","                x = [i.to(device) for i in data[:-1]]\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(model.forward(x[0]).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            train_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            train_R2.append(R2(np.array(pred), np.array(true)))\n","            train_MAE.append(MAE(np.array(true), np.array(pred)))\n","\n","        # performance in test set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in test_loader:\n","                x = [i.to(device) for i in data[:-1]]\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(model.forward(x[0]).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            test_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            test_R2.append(R2(np.array(pred), np.array(true)))\n","            test_MAE.append(MAE(np.array(true), np.array(pred)))\n","\n","            if epoch == 0 or test_R2[-1] > best[3]:\n","                best = [train_R2[-1], train_RMSE[-1], train_MAE[-1], test_R2[-1], test_RMSE[-1], test_MAE[-1], pred,\n","                        true, model]\n","\n","        # write report\n","        f.write(\n","            \"Epoch:%d loss: %f, R2:train set %.3f\\ttest set %.3f\\tRMSE:train set %.3f\\ttest set %.3f\\tMAE:train set %.3f\\ttest set %.3f\\n\" % (\n","            epoch + 1, global_loss / batch_size, train_R2[-1], test_R2[-1], train_RMSE[-1], test_RMSE[-1],\n","            train_MAE[-1], test_MAE[-1]))\n","\n","    # 4.Evaluation\n","    f.write(\"\\n\")\n","    # Performance in train set\n","    f.write(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_R2[-10:]).mean(), np.array(train_R2[-10:]).std(), best[0]))\n","    f.write(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_RMSE[-10:]).mean(), np.array(train_RMSE[-10:]).std(), best[1]))\n","    f.write(\"MAE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_MAE[-10:]).mean(), np.array(train_MAE[-10:]).std(), best[2]))\n","\n","    # Performance in test set\n","    f.write(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(test_R2[-10:]).mean(), np.array(test_R2[-10:]).std(), best[3]))\n","    f.write(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_RMSE[-10:]).mean(), np.array(test_RMSE[-10:]).std(), best[4]))\n","    f.write(\"MAE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_MAE[-10:]).mean(), np.array(test_MAE[-10:]).std(), best[5]))\n","\n","    f.close()\n","\n","    # Performance in train set\n","    print(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_R2[-10:]).mean(), np.array(train_R2[-10:]).std(), best[0]))\n","    print(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_RMSE[-10:]).mean(), np.array(train_RMSE[-10:]).std(), best[1]))\n","    print(\"MAE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_MAE[-10:]).mean(), np.array(train_MAE[-10:]).std(), best[2]))\n","\n","    # Performance in test set\n","    print(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(test_R2[-10:]).mean(), np.array(test_R2[-10:]).std(), best[3]))\n","    print(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_RMSE[-10:]).mean(), np.array(test_RMSE[-10:]).std(), best[4]))\n","    print(\"MAE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_MAE[-10:]).mean(), np.array(test_MAE[-10:]).std(), best[5]))\n","\n","    # 5.Figure\n","    import matplotlib.pyplot as plt\n","    import seaborn as sns\n","\n","    fig = plt.figure(dpi=500, figsize=(10, 5))\n","\n","    # Training Fig\n","    plt.subplot(1, 2, 1)\n","    steps = np.linspace(1, t, t)\n","    plt.plot(steps, train_R2, color=[236 / 255, 164 / 255, 124 / 255])\n","    plt.plot(steps, test_R2, color=[117 / 255, 157 / 255, 219 / 255])\n","    # Beautify\n","    plt.legend([\"train set\", \"test set\"], loc=\"upper left\", prop={'size': 8})\n","    plt.xlabel(\"Epoch\", fontsize=10)\n","    plt.ylabel(\"R$^2$\", fontsize=10)\n","    plt.title(\"The R$^2$ of train & test set during training\", fontsize=13)\n","\n","    # Test set performance\n","    plt.subplot(1, 2, 2)\n","    tr = np.array(best[7]).flatten()\n","    pr = np.array(best[6]).flatten()\n","    plt.scatter(pr, tr, alpha=0.7, marker=\".\")\n","    plt.xlabel(\"Predicted E$_a$ (kcal mol$^-$$^1$)\", fontsize=10)\n","    plt.ylabel(\"Observed E$_a$ (kcal mol$^-$$^1$)\", fontsize=10)\n","    x = np.linspace(10, 45, 8)\n","    y = np.linspace(10, 45, 8)\n","    plt.plot(x, y, linestyle=\"--\", color=\"r\")\n","    plt.title(\"Test set performance\", fontsize=15)\n","    fig.suptitle(\"GCN for SNAR dataset\", fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(\"%s/Performance_Figure.png\" % dir_path)\n","    plt.show()\n","\n","    torch.save(best[-1], \"%s/model.pth\" % dir_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uiIDjPGodtj7"},"outputs":[],"source":["# GAT\n","rs_list = [1]\n","\n","for rs in rs_list:\n","    # 1. import data\n","    data = pd.read_excel(\"/content/drive/MyDrive/MMHRP/data/SNAR/SNAR_data.xlsx\")\n","    random_state = rs\n","\n","    data = data.sample(random_state=random_state, frac=1).reset_index(drop=True)\n","\n","    # 2. build dataset & dataloader\n","    rxn_dataset = list()\n","\n","    for batch in tqdm(range(data.shape[0])):\n","        meta = list()\n","        # rea\n","        rea1 = data.loc[batch][\"Substrate SMILES\"]\n","        rea2 = data.loc[batch][\"Nucleophile SMILES\"]\n","        prod = data.loc[batch][\"Product SMILES\"]\n","        # sol\n","        sol = list()\n","        sol = data.loc[batch][\"Solvent\"].split(\".\")\n","\n","        meta.append(smis_to_graph([rea1, rea2, prod] + sol))\n","\n","        # activation energy\n","        meta.append(data.loc[batch][\"exp_activation_energy\"])\n","\n","        rxn_dataset.append(meta)\n","\n","    # report\n","    dir_path = \"/content/drive/MyDrive/MMHRP/exp/SNAR/SNAR_GAT_rs=%s_%s\" % (random_state, datetime.datetime.now())\n","    os.mkdir(\"%s\" % dir_path)\n","    f = open(\"%s/Model_Training_Report.txt\" % dir_path, mode=\"w\")\n","\n","    # split of train & test set\n","    ratio = 0.8\n","    batch_size = 32\n","    batch = len(rxn_dataset)\n","    train_set = rxn_dataset[0: int(ratio * batch)]\n","    test_set = rxn_dataset[int(ratio * batch) + 1:]\n","    # data_loader\n","    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n","\n","    test_RMSE = list()\n","    test_R2 = list()\n","    test_MAE = list()\n","    train_R2 = list()\n","    train_RMSE = list()\n","    train_MAE = list()\n","    pred = list()\n","    true = list()\n","\n","    # 3. training of the model\n","    # params\n","    t = 1000\n","    lr = 1e-5\n","    num_feature = 8\n","\n","    # use gpu\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # model\n","    model = GAT(node_feature_num=num_feature,\n","                channels=[32, 64],\n","                heads=4)\n","    model = model.to(device)\n","    opti = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n","\n","    criterion = nn.MSELoss()\n","\n","    # writedown params\n","    f.write(\"params:\\n\")\n","    f.write(\"random_state=%s\\n\" % random_state)\n","    f.write(\"ratio=%s\\n\" % ratio)\n","    f.write(\"batch_size=%s\\n\" % batch_size)\n","    f.write(\"t=%s\\n\" % t)\n","    f.write(\"lr=%s\\n\" % lr)\n","\n","    # Training\n","\n","    # best performance\n","    best = [0, 0, 0, 0, 0, 0, [], [],\n","            []]  # train_R2, train_RMSE, train_MAE, test_R2, test_RMSE, test_MAE test_predict, test_true, model\n","\n","    f.write(\"\\nStart training\\n\")\n","\n","    for epoch in tqdm(range(t)):\n","        # Training\n","        global_loss = torch.tensor([0.])\n","\n","        for data in train_loader:\n","            x = [i.to(device) for i in data[:-1]]\n","            y = torch.unsqueeze(data[-1], dim=1).to(device)\n","            loss = criterion(model.forward(x[0]), y)\n","            opti.zero_grad()\n","            loss.backward()\n","            opti.step()\n","            global_loss += loss.item()\n","\n","        # record of loss during training\n","        # performance in train set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in train_loader:\n","                x = [i.to(device) for i in data[:-1]]\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(model.forward(x[0]).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            train_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            train_R2.append(R2(np.array(pred), np.array(true)))\n","            train_MAE.append(MAE(np.array(true), np.array(pred)))\n","\n","        # performance in test set\n","        with torch.no_grad():\n","            pred = list()\n","            true = list()\n","            for data in test_loader:\n","                x = [i.to(device) for i in data[:-1]]\n","                tr = list(torch.unsqueeze(data[-1], dim=1).detach().numpy())\n","                pr = list(model.forward(x[0]).cpu().detach().numpy())\n","                pred += pr\n","                true += tr\n","            test_RMSE.append(RMSE(np.array(pred), np.array(true)))\n","            test_R2.append(R2(np.array(pred), np.array(true)))\n","            test_MAE.append(MAE(np.array(true), np.array(pred)))\n","\n","            if epoch == 0 or test_R2[-1] > best[3]:\n","                best = [train_R2[-1], train_RMSE[-1], train_MAE[-1], test_R2[-1], test_RMSE[-1], test_MAE[-1], pred,\n","                        true, model]\n","\n","        # write report\n","        f.write(\n","            \"Epoch:%d loss: %f, R2:train set %.3f\\ttest set %.3f\\tRMSE:train set %.3f\\ttest set %.3f\\tMAE:train set %.3f\\ttest set %.3f\\n\" % (\n","            epoch + 1, global_loss / batch_size, train_R2[-1], test_R2[-1], train_RMSE[-1], test_RMSE[-1],\n","            train_MAE[-1], test_MAE[-1]))\n","\n","    # 4.Evaluation\n","    f.write(\"\\n\")\n","    # Performance in train set\n","    f.write(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_R2[-10:]).mean(), np.array(train_R2[-10:]).std(), best[0]))\n","    f.write(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_RMSE[-10:]).mean(), np.array(train_RMSE[-10:]).std(), best[1]))\n","    f.write(\"MAE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_MAE[-10:]).mean(), np.array(train_MAE[-10:]).std(), best[2]))\n","\n","    # Performance in test set\n","    f.write(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(test_R2[-10:]).mean(), np.array(test_R2[-10:]).std(), best[3]))\n","    f.write(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_RMSE[-10:]).mean(), np.array(test_RMSE[-10:]).std(), best[4]))\n","    f.write(\"MAE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_MAE[-10:]).mean(), np.array(test_MAE[-10:]).std(), best[5]))\n","\n","    f.close()\n","\n","    # Performance in train set\n","    print(\"R2 of train set is:%.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_R2[-10:]).mean(), np.array(train_R2[-10:]).std(), best[0]))\n","    print(\"RMSE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_RMSE[-10:]).mean(), np.array(train_RMSE[-10:]).std(), best[1]))\n","    print(\"MAE of train set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(train_MAE[-10:]).mean(), np.array(train_MAE[-10:]).std(), best[2]))\n","\n","    # Performance in test set\n","    print(\"R2 of test set is:%.3f+-%.3f\\tbest:%f\\n\" % (\n","    np.array(test_R2[-10:]).mean(), np.array(test_R2[-10:]).std(), best[3]))\n","    print(\"RMSE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_RMSE[-10:]).mean(), np.array(test_RMSE[-10:]).std(), best[4]))\n","    print(\"MAE of test set is: %.3f+-%f\\tbest:%f\\n\" % (\n","    np.array(test_MAE[-10:]).mean(), np.array(test_MAE[-10:]).std(), best[5]))\n","\n","    # 5.Figure\n","    import matplotlib.pyplot as plt\n","    import seaborn as sns\n","\n","    fig = plt.figure(dpi=500, figsize=(10, 5))\n","\n","    # Training Fig\n","    plt.subplot(1, 2, 1)\n","    steps = np.linspace(1, t, t)\n","    plt.plot(steps, train_R2, color=[236 / 255, 164 / 255, 124 / 255])\n","    plt.plot(steps, test_R2, color=[117 / 255, 157 / 255, 219 / 255])\n","    # Beautify\n","    plt.legend([\"train set\", \"test set\"], loc=\"upper left\", prop={'size': 8})\n","    plt.xlabel(\"Epoch\", fontsize=10)\n","    plt.ylabel(\"R$^2$\", fontsize=10)\n","    plt.title(\"The R$^2$ of train & test set during training\", fontsize=13)\n","\n","    # Test set performance\n","    plt.subplot(1, 2, 2)\n","    tr = np.array(best[7]).flatten()\n","    pr = np.array(best[6]).flatten()\n","    plt.scatter(pr, tr, alpha=0.7, marker=\".\")\n","    plt.xlabel(\"Predicted E$_a$ (kcal mol$^-$$^1$)\", fontsize=10)\n","    plt.ylabel(\"Observed E$_a$ (kcal mol$^-$$^1$)\", fontsize=10)\n","    x = np.linspace(10, 45, 8)\n","    y = np.linspace(10, 45, 8)\n","    plt.plot(x, y, linestyle=\"--\", color=\"r\")\n","    plt.title(\"Test set performance\", fontsize=15)\n","    fig.suptitle(\"GAT for SNAR dataset\", fontsize=16)\n","    plt.tight_layout()\n","    plt.savefig(\"%s/Performance_Figure.png\" % dir_path)\n","    plt.show()\n","\n","    torch.save(best[-1], \"%s/model.pth\" % dir_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rL3sFqcPd6pG"},"outputs":[],"source":["# rf\n","rs_list = [1, 2, 3, 4, 5]\n","for rs in rs_list:\n","  # 1. import data\n","  data = pd.read_excel(\"/content/drive/MyDrive/MMHRP/data/SNAR/SNAR_fp.xlsx\")\n","  random_state = rs\n","  data = data.sample(random_state=random_state, frac=1).reset_index(drop=True)\n","  # 2. build dataset & dataloader\n","  rxnfp_set = list()\n","  drfp_set = list()\n","  yield_set = list()\n","  len_rxnfp = 0\n","  len_drfp = 0\n","\n","  for batch in tqdm(range(data.shape[0])):\n","      # features\n","      rxnfp = read_rxnfp(data.loc[batch][\"rxnfp\"])\n","      len_rxnfp = rxnfp.shape[0]\n","      drfp = read_drfp(data.loc[batch][\"drfp\"])\n","      len_drfp = drfp.shape[0]\n","      # label\n","      y = float(data.loc[batch][\"exp_activation_energy\"])\n","\n","      rxnfp_set.append(rxnfp)\n","      drfp_set.append(drfp)\n","      yield_set.append(y)\n","\n","  # split of train & test set\n","  ratio = 0.8\n","  # rxnfp\n","  batch = len(rxnfp_set)\n","  rxnfp_trainset = [rxnfp_set[0: int(ratio * batch)], yield_set[0: int(ratio * batch)]]\n","  rxnfp_testset = [rxnfp_set[int(ratio * batch) + 1:], yield_set[int(ratio * batch) + 1:]]\n","\n","  # drfp\n","  batch = len(drfp_set)\n","  drfp_trainset = [drfp_set[0: int(ratio * batch)], yield_set[0: int(ratio * batch)]]\n","  drfp_testset = [drfp_set[int(ratio * batch) + 1:], yield_set[int(ratio * batch) + 1:]]\n","\n","  # report\n","  dir_path = \"/content/drive/MyDrive/MMHRP/exp/SNAR/SNAR_RXNFP&DRFP_rs=%s_%s\" % (random_state, datetime.datetime.now())\n","  os.mkdir(\"%s\" % dir_path)\n","  f = open(\"%s/Model_Training_Report.txt\" % dir_path, mode=\"w\")\n","\n","  # record\n","  f.write(\"params:\\n\")\n","  f.write(\"random_state=%s\\n\" % random_state)\n","  f.write(\"ratio=%s\\n\" % ratio)\n","  f.write(\"length of RXNFP=%s\\n\" % len_rxnfp)\n","  f.write(\"length of DRFP=%s\\n\" % len_drfp)\n","  f.write(\"\\n\")\n","\n","  # Machine Learning methods\n","  # RandomForest\n","  from sklearn.ensemble import RandomForestRegressor\n","\n","  # Train\n","  print(\"RandomForest Start Training\")\n","  start = time.time()\n","\n","  rxnfp_rf = RandomForestRegressor(n_estimators=150, random_state=0)\n","  drfp_rf = RandomForestRegressor(n_estimators=150, random_state=0)\n","  rxnfp_rf.fit(rxnfp_trainset[0], rxnfp_trainset[1])\n","  drfp_rf.fit(drfp_trainset[0], drfp_trainset[1])\n","\n","  print(\"Finish Training\")\n","  print(\"Training Time: %.2f s\" % (time.time()-start))#截止时间\n","\n","  # Eval\n","  # trainset\n","  # R2\n","  rxnfp_train_R2 = R2(rxnfp_rf.predict(rxnfp_trainset[0]), np.array(rxnfp_trainset[1]))\n","  drfp_train_R2 = R2(drfp_rf.predict(drfp_trainset[0]), np.array(drfp_trainset[1]))\n","  # RMSE\n","  rxnfp_train_RMSE = RMSE(rxnfp_rf.predict(rxnfp_trainset[0]), np.array(rxnfp_trainset[1]))\n","  drfp_train_RMSE = RMSE(drfp_rf.predict(drfp_trainset[0]), np.array(drfp_trainset[1]))\n","  # MAE\n","  rxnfp_train_MAE = MAE(y_pred=rxnfp_rf.predict(rxnfp_trainset[0]), y_true=np.array(rxnfp_trainset[1]))\n","  drfp_train_MAE = MAE(y_pred=drfp_rf.predict(drfp_trainset[0]), y_true=np.array(drfp_trainset[1]))\n","\n","  # R2\n","  rxnfp_test_R2 = R2(rxnfp_rf.predict(rxnfp_testset[0]), np.array(rxnfp_testset[1]))\n","  drfp_test_R2 = R2(drfp_rf.predict(drfp_testset[0]), np.array(drfp_testset[1]))\n","  # RMSE\n","  rxnfp_test_RMSE = RMSE(rxnfp_rf.predict(rxnfp_testset[0]), np.array(rxnfp_testset[1]))\n","  drfp_test_RMSE = RMSE(drfp_rf.predict(drfp_testset[0]), np.array(drfp_testset[1]))\n","  # MAE\n","  rxnfp_test_MAE = MAE(y_pred=rxnfp_rf.predict(rxnfp_testset[0]), y_true=np.array(rxnfp_testset[1]))\n","  drfp_test_MAE = MAE(y_pred=drfp_rf.predict(drfp_testset[0]), y_true=np.array(drfp_testset[1]))\n","\n","  # Record\n","  f.write(\"RandomForest:\\n\")\n","  f.write(\"params:\\n\")\n","  f.write(\"rxnfp RF:%s\\n\" % rxnfp_rf.n_estimators)\n","  f.write(\"drfp RF:%s\\n\" % drfp_rf.n_estimators)\n","\n","  f.write(\"rxnfp:\\n\")\n","  f.write(\"rxnfp_train_R2=%s\\n\" % rxnfp_train_R2)\n","  f.write(\"rxnfp_train_RMSE=%s\\n\" % rxnfp_train_RMSE)\n","  f.write(\"rxnfp_train_MAE=%s\\n\" % rxnfp_train_MAE)\n","  f.write(\"rxnfp_test_R2=%s\\n\" % rxnfp_test_R2)\n","  f.write(\"rxnfp_test_RMSE=%s\\n\" % rxnfp_test_RMSE)\n","  f.write(\"rxnfp_test_MAE=%s\\n\" % rxnfp_test_MAE)\n","  f.write(\"drfp:\\n\")\n","  f.write(\"drfp_train_R2=%s\\n\" % drfp_train_R2)\n","  f.write(\"drfp_train_RMSE=%s\\n\" % drfp_train_RMSE)\n","  f.write(\"drfp_train_MAE=%s\\n\" % drfp_train_MAE)\n","  f.write(\"drfp_test_R2=%s\\n\" % drfp_test_R2)\n","  f.write(\"drfp_test_RMSE=%s\\n\" % drfp_test_RMSE)\n","  f.write(\"drfp_test_MAE=%s\\n\" % drfp_test_MAE)\n","  f.write(\"\\n\")\n","\n","  # xgboost\n","  from xgboost import XGBRegressor\n","\n","  # Train\n","  print(\"XGBoost Start Training\")\n","  start = time.time()\n","\n","  rxnfp_xgb = XGBRegressor(n_estimators=300)\n","  drfp_xgb = XGBRegressor(n_estimators=300)\n","  rxnfp_xgb.fit(rxnfp_trainset[0], rxnfp_trainset[1])\n","  drfp_xgb.fit(drfp_trainset[0], drfp_trainset[1])\n","\n","  print(\"Finish Training\")\n","  print(\"Training Time: %.2f s\" % (time.time()-start))#截止时间\n","\n","  # Eval\n","  # trainset\n","  # R2\n","  rxnfp_train_R2 = R2(rxnfp_xgb.predict(rxnfp_trainset[0]), np.array(rxnfp_trainset[1]))\n","  drfp_train_R2 = R2(drfp_xgb.predict(drfp_trainset[0]), np.array(drfp_trainset[1]))\n","  # RMSE\n","  rxnfp_train_RMSE = RMSE(rxnfp_xgb.predict(rxnfp_trainset[0]), np.array(rxnfp_trainset[1]))\n","  drfp_train_RMSE = RMSE(drfp_xgb.predict(drfp_trainset[0]), np.array(drfp_trainset[1]))\n","  # MAE\n","  rxnfp_train_MAE = MAE(y_pred=rxnfp_xgb.predict(rxnfp_trainset[0]), y_true=np.array(rxnfp_trainset[1]))\n","  drfp_train_MAE = MAE(y_pred=drfp_xgb.predict(drfp_trainset[0]), y_true=np.array(drfp_trainset[1]))\n","\n","  # R2\n","  rxnfp_test_R2 = R2(rxnfp_xgb.predict(rxnfp_testset[0]), np.array(rxnfp_testset[1]))\n","  drfp_test_R2 = R2(drfp_xgb.predict(drfp_testset[0]), np.array(drfp_testset[1]))\n","  # RMSE\n","  rxnfp_test_RMSE = RMSE(rxnfp_xgb.predict(rxnfp_testset[0]), np.array(rxnfp_testset[1]))\n","  drfp_test_RMSE = RMSE(drfp_xgb.predict(drfp_testset[0]), np.array(drfp_testset[1]))\n","  # MAE\n","  rxnfp_test_MAE = MAE(y_pred=rxnfp_xgb.predict(rxnfp_testset[0]), y_true=np.array(rxnfp_testset[1]))\n","  drfp_test_MAE = MAE(y_pred=drfp_xgb.predict(drfp_testset[0]), y_true=np.array(drfp_testset[1]))\n","\n","  # Record\n","  f.write(\"XGBoost:\\n\")\n","  f.write(\"params:\\n\")\n","  f.write(\"rxnfp XGB:%s\\n\" % rxnfp_xgb.n_estimators)\n","  f.write(\"drfp XGB:%s\\n\" % drfp_xgb.n_estimators)\n","\n","  f.write(\"rxnfp:\\n\")\n","  f.write(\"rxnfp_train_R2=%s\\n\" % rxnfp_train_R2)\n","  f.write(\"rxnfp_train_RMSE=%s\\n\" % rxnfp_train_RMSE)\n","  f.write(\"rxnfp_train_MAE=%s\\n\" % rxnfp_train_MAE)\n","  f.write(\"rxnfp_test_R2=%s\\n\" % rxnfp_test_R2)\n","  f.write(\"rxnfp_test_RMSE=%s\\n\" % rxnfp_test_RMSE)\n","  f.write(\"rxnfp_test_MAE=%s\\n\" % rxnfp_test_MAE)\n","  f.write(\"drfp:\\n\")\n","  f.write(\"drfp_train_R2=%s\\n\" % drfp_train_R2)\n","  f.write(\"drfp_train_RMSE=%s\\n\" % drfp_train_RMSE)\n","  f.write(\"drfp_train_MAE=%s\\n\" % drfp_train_MAE)\n","  f.write(\"drfp_test_R2=%s\\n\" % drfp_test_R2)\n","  f.write(\"drfp_test_RMSE=%s\\n\" % drfp_test_RMSE)\n","  f.write(\"drfp_test_MAE=%s\\n\" % drfp_test_MAE)\n","  f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L08xmKf2fzwr"},"outputs":[],"source":["# rf\n","rs_list = [1,2,3,4,5]\n","for rs in rs_list:\n","  # 1. import data\n","  data = pd.read_excel(\"/content/drive/MyDrive/MMHRP/data/SNAR/SNAR_DFT.xlsx\")\n","  random_state = rs\n","  data = data.sample(random_state=random_state, frac=1).reset_index(drop=True)\n","  # 2. build dataset & dataloader\n","  dft_set = list()\n","  yield_set = list()\n","\n","  for batch in tqdm(range(data.shape[0])):\n","      # features\n","      dft = data.iloc[batch, :-1]\n","      # label\n","      y = float(data.loc[batch][\"exp_activation_energy\"])\n","\n","      dft_set.append(dft)\n","      yield_set.append(y)\n","\n","  # split of train & test set\n","  ratio = 0.8\n","  batch = len(dft_set)\n","  trainset = [dft_set[0: int(ratio * batch)], yield_set[0: int(ratio * batch)]]\n","  testset = [dft_set[int(ratio * batch) + 1:], yield_set[int(ratio * batch) + 1:]]\n","\n","  # report\n","  dir_path = \"/content/drive/MyDrive/MMHRP/exp/SNAR/SNAR_DFT_rs=%s_%s\" % (random_state, datetime.datetime.now())\n","  os.mkdir(\"%s\" % dir_path)\n","  f = open(\"%s/Model_Training_Report.txt\" % dir_path, mode=\"w\")\n","\n","  # record\n","  f.write(\"params:\\n\")\n","  f.write(\"random_state=%s\\n\" % random_state)\n","  f.write(\"ratio=%s\\n\" % ratio)\n","  f.write(\"\\n\")\n","\n","  # Machine Learning methods\n","  # RandomForest\n","  from sklearn.ensemble import RandomForestRegressor\n","\n","  # Train\n","  print(\"RandomForest Start Training\")\n","  start = time.time()\n","\n","  rf = RandomForestRegressor(n_estimators=150, random_state=0)\n","  rf.fit(trainset[0], trainset[1])\n","\n","  print(\"Finish Training\")\n","  print(\"Training Time: %.2f s\" % (time.time()-start))#截止时间\n","\n","  # Eval\n","  # trainset\n","  # R2\n","  train_R2 = R2(rf.predict(trainset[0]), np.array(trainset[1]))\n","  # RMSE\n","  train_RMSE = RMSE(rf.predict(trainset[0]), np.array(trainset[1]))\n","  # MAE\n","  train_MAE = MAE(y_pred=rf.predict(trainset[0]), y_true=np.array(trainset[1]))\n","\n","  # R2\n","  test_R2 = R2(rf.predict(testset[0]), np.array(testset[1]))\n","  # RMSE\n","  test_RMSE = RMSE(rf.predict(testset[0]), np.array(testset[1]))\n","  # MAE\n","  test_MAE = MAE(y_pred=rf.predict(testset[0]), y_true=np.array(testset[1]))\n","\n","  # Record\n","  f.write(\"RandomForest:\\n\")\n","  f.write(\"params:\\n\")\n","  f.write(\"RF:%s\\n\" % rf.n_estimators)\n","\n","  f.write(\"train_R2=%s\\n\" % train_R2)\n","  f.write(\"train_RMSE=%s\\n\" % train_RMSE)\n","  f.write(\"train_MAE=%s\\n\" % train_MAE)\n","  f.write(\"test_R2=%s\\n\" % test_R2)\n","  f.write(\"test_RMSE=%s\\n\" % test_RMSE)\n","  f.write(\"test_MAE=%s\\n\" % test_MAE)\n","  f.write(\"\\n\")\n","\n","  # xgboost\n","  from xgboost import XGBRegressor\n","\n","  # Train\n","  print(\"XGBoost Start Training\")\n","  start = time.time()\n","\n","  xgb = XGBRegressor(n_estimators=300)\n","  xgb.fit(trainset[0], trainset[1])\n","\n","  print(\"Finish Training\")\n","  print(\"Training Time: %.2f s\" % (time.time()-start))#截止时间\n","\n","  # Eval\n","  # trainset\n","  # R2\n","  train_R2 = R2(xgb.predict(trainset[0]), np.array(trainset[1]))\n","  # RMSE\n","  train_RMSE = RMSE(xgb.predict(trainset[0]), np.array(trainset[1]))\n","  # MAE\n","  train_MAE = MAE(y_pred=xgb.predict(trainset[0]), y_true=np.array(trainset[1]))\n","\n","  # R2\n","  test_R2 = R2(xgb.predict(testset[0]), np.array(testset[1]))\n","  # RMSE\n","  test_RMSE = RMSE(xgb.predict(testset[0]), np.array(testset[1]))\n","  # MAE\n","  test_MAE = MAE(y_pred=xgb.predict(testset[0]), y_true=np.array(testset[1]))\n","\n","  # Record\n","  f.write(\"XGBoost:\\n\")\n","  f.write(\"params:\\n\")\n","  f.write(\"XGB:%s\\n\" % xgb.n_estimators)\n","  f.write(\"train_R2=%s\\n\" % train_R2)\n","  f.write(\"train_RMSE=%s\\n\" % train_RMSE)\n","  f.write(\"train_MAE=%s\\n\" % train_MAE)\n","  f.write(\"test_R2=%s\\n\" % test_R2)\n","  f.write(\"test_RMSE=%s\\n\" % test_RMSE)\n","  f.write(\"test_MAE=%s\\n\" % test_MAE)\n","  f.close()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOlrfe1g0bXf1U26toRl9ez"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}